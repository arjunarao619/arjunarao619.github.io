@inproceedings{
me,
title={Counteracting Adversarial Attacks in Autonomous Driving},
author={Qi Sun and ArjunAshok Rao and Xufeng Yao and Bei Yu and Shiyan Hu},
booktitle={IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
year={2020},
url={http://www.cse.cuhk.edu.hk/~byu/papers/C105-ICCAD2020-Stereo.pdf},
}

@inproceedings{
tsipras2018robustness,
title={Robustness May Be at Odds with Accuracy},
author={Dimitris Tsipras and Shibani Santurkar and Logan Engstrom and Alexander Turner and Aleksander Madry},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SyxAb30cY7},
}
@inproceedings{10.5555/3305381.3305487,
author = {Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
title = {Sharp Minima Can Generalize for Deep Nets},
year = {2017},
publisher = {JMLR.org},
abstract = {Despite their overwhelming capacity to overfit, deep learning architectures tend to generalize relatively well to unseen data, allowing them to be deployed in practice. However, explaining why this is the case is still an open area of research. One standing hypothesis that is gaining popularity, e.g. Hochreiter & Schmidhuber (1997); Keskar et al. (2017), is that the flatness of minima of the loss function found by stochastic gradient based methods results in good generalization. This paper argues that most notions of flatness are problematic for deep models and can not be directly applied to explain generalization. Specifically, when focusing on deep networks with rectifier units, we can exploit the particular geometry of parameter space induced by the inherent symmetries that these architectures exhibit to build equivalent models corresponding to arbitrarily sharper minima. Furthermore, if we allow to reparametrize a function, the geometry of its parameters can change drastically without affecting its generalization properties.},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {1019â€“1028},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}

@inproceedings{zeng2019adversarial,
  title={Adversarial attacks beyond the image space},
  author={Zeng, Xiaohui and Liu, Chenxi and Wang, Yu-Siang and Qiu, Weichao and Xie, Lingxi and Tai, Yu-Wing and Tang, Chi-Keung and Yuille, Alan L},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4302--4311},
  year={2019}
}
@article{Tsipras2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1805.12152v5},
author = {Tsipras, Dimitris and Turner, Alexander},
eprint = {arXiv:1805.12152v5},
file = {:Users/arjunrao/Dropbox/Papers-adversarial/Tsipras, Turner - 2018 - Robustness May Be at Odds with Accuracy.pdf:pdf},
mendeley-groups = {Research Statement},
pages = {1--24},
title = {{Robustness May Be at Odds with Accuracy}},
year = {2018}
}
@article{engstrom2019adversarial,
  title={Adversarial robustness as a prior for learned representations},
  author={Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Tran, Brandon and Madry, Aleksander},
  journal={arXiv preprint arXiv:1906.00945},
  year={2019}
}
@inproceedings{43405,
title	= {Explaining and Harnessing Adversarial Examples},
author	= {Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
year	= {2015},
URL	= {http://arxiv.org/abs/1412.6572},
booktitle	= {International Conference on Learning Representations}
}


@inproceedings{stutz2019disentangling,
  title={Disentangling adversarial robustness and generalization},
  author={Stutz, David and Hein, Matthias and Schiele, Bernt},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6976--6987},
  year={2019}
}
@inproceedings{chan2020thinks,
  title={What it Thinks is Important is Important: Robustness Transfers through Input Gradients},
  author={Chan, Alvin and Tay, Yi and Ong, Yew-Soon},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={332--341},
  year={2020}
}
